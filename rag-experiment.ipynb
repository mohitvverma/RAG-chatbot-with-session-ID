{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-22T18:37:12.401851Z",
     "start_time": "2024-06-22T18:37:12.397472Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "#collection = os.environ.get('COLLECTION', 'new_youtube_collection').strip()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T23:13:38.384504Z",
     "start_time": "2024-06-22T23:13:38.369629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import uuid\n",
    "session_id = uuid.uuid4()\n",
    "session_id = str(session_id)\n",
    "session_id"
   ],
   "id": "5f45bac4049bca77",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'705e6e16-b882-4450-837e-03ebba1eaf38'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T18:38:22.553828Z",
     "start_time": "2024-06-22T18:38:22.549373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.environ['USER'] = 'postgres'\n",
    "user = os.environ.get('USER', 'postgres').strip()\n",
    "print(user)\n"
   ],
   "id": "e5a9f11c3ae05cc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgres\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:44:59.254230Z",
     "start_time": "2024-06-22T05:44:59.252153Z"
    }
   },
   "cell_type": "code",
   "source": "#collection",
   "id": "c873393d2d2a08ec",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:45:00.856936Z",
     "start_time": "2024-06-22T05:45:00.118042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import logging\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, CSVLoader\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "#from langchain_openai import OpenAIEmbeddings"
   ],
   "id": "c623677d698f4b03",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:45:47.728835Z",
     "start_time": "2024-06-22T05:45:47.718246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "60cb2e5ead31d200",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:45:48.698812Z",
     "start_time": "2024-06-22T05:45:48.694412Z"
    }
   },
   "cell_type": "code",
   "source": "print(os.getenv(\"MISTRAL_API_KEY\"))",
   "id": "af3eaa058412fbab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W7jHpjnfU7vGjJXSChnMjFJa5XqheIv9\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:24.623463Z",
     "start_time": "2024-06-21T18:09:24.620806Z"
    }
   },
   "cell_type": "code",
   "source": "model_name=\"mistralai/Mistral-7B-Instruct-v0.1\"",
   "id": "63e58710b4076563",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:24.628146Z",
     "start_time": "2024-06-21T18:09:24.625125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#_, file_extension = os.path.splitext()\n",
    "file_path=\"/Users/mohitverma/Documents/Etech-RAG-Chatbot/Etech-RAG-E2E/qevalprofaq 5.csv\"\n",
    "loader = CSVLoader(file_path)"
   ],
   "id": "edd3d82219c7097b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:24.636356Z",
     "start_time": "2024-06-21T18:09:24.631378Z"
    }
   },
   "cell_type": "code",
   "source": "print(loader.load()[0].page_content)",
   "id": "646d983fef68503",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breadcrumb_title: Can a user view my message if I am replying to some other user in chat feature?\n",
      "post_content: Except for an agent, every user role will have two chat modes on their consoles. These include a Private mode and a general reply mode. A user can use a private mode tab to establish a private conversation for evaluation with other user, thus shielding off other users to view their messages. Similarly, a user can use a reply mode to send the messages, which could be viewed by all the other users.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:24.644112Z",
     "start_time": "2024-06-21T18:09:24.638012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "docs = text_splitter.split_documents(data)"
   ],
   "id": "8533bfbdb29f4386",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:36.234970Z",
     "start_time": "2024-06-21T18:09:24.644976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\"sentence-transformers/all-mpnet-base-v2\")"
   ],
   "id": "4f1bab8f5e9286fa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:36.879394Z",
     "start_time": "2024-06-21T18:09:36.236969Z"
    }
   },
   "cell_type": "code",
   "source": "model=HuggingFaceEndpoint(repo_id=model_name, HUGGINGFACEHUB_API_TOKEN=\"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\")",
   "id": "1e268aac95f2bd9b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! HUGGINGFACEHUB_API_TOKEN is not default parameter.\n",
      "                    HUGGINGFACEHUB_API_TOKEN was transferred to model_kwargs.\n",
      "                    Please make sure that HUGGINGFACEHUB_API_TOKEN is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/mohitverma/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:36.887426Z",
     "start_time": "2024-06-21T18:09:36.880776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ],
   "id": "2eb2684a060b6df9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:37.124411Z",
     "start_time": "2024-06-21T18:09:36.888510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "llm = HuggingFaceEndpoint(repo_id=repo_id,\n",
    "                          max_length=128,\n",
    "                          temperature=0.7)"
   ],
   "id": "ef6cd29971eb67",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/mohitverma/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "`PGVector.from_documents(documents=docs,\n",
    "                                embeddings=HuggingFaceInstructEmbeddings(),)"
   ],
   "id": "9c6eca789866110f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:40.390276Z",
     "start_time": "2024-06-21T18:09:37.127610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ],
   "id": "6f890959b987c51",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:11:57.167685Z",
     "start_time": "2024-06-21T18:11:45.984276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from unittest import loader\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from logger import logging\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, CSVLoader\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.document_loaders import UnstructuredExcelLoader\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from db_connector import connection_string\n",
    "\n",
    "from constants import *\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "class DataIngestionProcessing:\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def split_data(self):\n",
    "        # Determine the file type based on the extension\n",
    "        _ ,file_extension = os.path.splitext(self.file_path)\n",
    "\n",
    "        if file_extension.lower() == '.csv':\n",
    "            logging.info(f\"Reading CSV file : {self.file_path}\")\n",
    "            print(\"Reading CSV file\")\n",
    "            loader = CSVLoader(self.file_path)\n",
    "\n",
    "        elif file_extension.lower() == '.xlsx':\n",
    "            logging.info(f\"Reading Excel file : {self.file_path}\")\n",
    "            loader=UnstructuredExcelLoader(self.file_path, mode=\"elements\")\n",
    "\n",
    "        elif file_extension.lower() == '.pdf':\n",
    "            logging.info(f\"Reading PDF file {self.file_path}\")\n",
    "            loader=PyPDFLoader(self.file_path)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"File extension {file_extension} not supported\")\n",
    "\n",
    "\n",
    "        data = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size= 1000, chunk_overlap=150)\n",
    "        docs = text_splitter.split_documents(data)\n",
    "        return docs\n",
    "\n",
    "\n",
    "    def push_data(self, docs):\n",
    "        #PGVector.delete_collection(PGSQL_COLLECTION)\n",
    "        print(f\"{self.file_path} is Pushed successfully into {PGSQL_COLLECTION}\")\n",
    "        PGVector.from_documents(\n",
    "            documents=docs,\n",
    "            embedding=embeddings,\n",
    "            collection_name=PGSQL_COLLECTION,\n",
    "            connection_string= connection_string,\n",
    "            pre_delete_collection=False\n",
    "            )\n",
    "        print(f\"{self.file_path} is Pushed successfully into {PGSQL_COLLECTION}\")\n",
    "        \n",
    "    \n",
    "doc_processor = DataIngestionProcessing(file_path=\"/Users/mohitverma/Documents/Etech-RAG-Chatbot/Etech-RAG-E2E/qevalprofaq 5.csv\")\n",
    "docs = doc_processor.split_data()\n",
    "doc_processor.push_data(docs)\n"
   ],
   "id": "e9b7bcf212ac08d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file\n",
      "/Users/mohitverma/Documents/Etech-RAG-Chatbot/Etech-RAG-E2E/qevalprofaq 5.csv is Pushed successfully into etech_collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/langchain_community/vectorstores/pgvector.py:322: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata.Please note that filtering operators have been changed when using JSOB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create adb migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mohitverma/Documents/Etech-RAG-Chatbot/Etech-RAG-E2E/qevalprofaq 5.csv is Pushed successfully into etech_collection\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:42.778809Z",
     "start_time": "2024-06-21T18:09:42.778710Z"
    }
   },
   "cell_type": "code",
   "source": "from langchain.embeddings import SentenceTransformerEmbeddings",
   "id": "970bcc6ec6013efe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "52fa184a9ed91e16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def delete_collection(self) -> None:\n",
    "    self.logger.debug(\"Trying to delete collection\")\n",
    "    with Session(self._conn) as session:\n",
    "        collection = self.get_collection(session)\n",
    "        if not collection:\n",
    "            self.logger.warning(\"Collection not found\")\n",
    "            return\n",
    "        session.delete(collection)\n",
    "        session.commit()"
   ],
   "id": "614d387f939aebf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f1465bfc3fc0dbd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:50:52.745519Z",
     "start_time": "2024-06-22T15:50:52.720126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "#from langchain_core.language_models.chat_models import LangSmithParams\n",
    "#from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_ai21 import ChatAI21\n",
    "from langchain_ai21 import AI21Embeddings\n",
    "#from langchain_mistralai.embeddings import MistralAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(os.environ.get(\"AI21_API_KEY\",\"KVlTLRfckUbPN81UiTC6OPtO1tjzLbC6\"))\n",
    "os.environ.get(\"AI21_API_KEY\",\"KVlTLRfckUbPN81UiTC6OPtO1tjzLbC6\")\n",
    "\n",
    "# Load data\n",
    "loader = CSVLoader(\"/Users/mohitverma/Documents/Etech-RAG-Chatbot/Etech-RAG-E2E/qevalprofaq 5.csv\")\n",
    "docs = loader.load()\n",
    "# Split text into chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "# Define the embedding model\n",
    "embeddings = AI21Embeddings()\n",
    "# Create the vector store \n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "# Define a retriever interface\n",
    "retriever = vector.as_retriever()\n",
    "# Define LLM\n",
    "model = ChatAI21(temperature=0.0, max_tokens=4096)\n",
    "# Define prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "# Create a retrieval chain to answer questions\n",
    "document_chain = create_stuff_documents_chain(model, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "response = retrieval_chain.invoke({\"input\": \"What were the two main things the author worked on before college?\"})\n",
    "print(response[\"answer\"])"
   ],
   "id": "6127d2bfabf56c60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KVlTLRfckUbPN81UiTC6OPtO1tjzLbC6\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CSVLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAI21_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKVlTLRfckUbPN81UiTC6OPtO1tjzLbC6\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Load data\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m loader \u001B[38;5;241m=\u001B[39m \u001B[43mCSVLoader\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/Users/mohitverma/Documents/Etech-RAG-Chatbot/Etech-RAG-E2E/qevalprofaq 5.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     21\u001B[0m docs \u001B[38;5;241m=\u001B[39m loader\u001B[38;5;241m.\u001B[39mload()\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Split text into chunks \u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'CSVLoader' is not defined"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:55:54.411698Z",
     "start_time": "2024-06-22T15:55:54.349697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(os.environ.get(\"AI21_API_KEY\",\"KVlTLRfckUbPN81UiTC6OPtO1tjzLbC6\"))\n",
    "os.environ.get(\"AI21_API_KEY\",\"KVlTLRfckUbPN81UiTC6OPtO1tjzLbC6\")\n",
    "embeddings = AI21Embeddings(api_key='KVlTLRfckUbPN81UiTC6OPtO1tjzLbC6')\n",
    "llm=ChatAI21(model='jamba-instruct',temperature=0.0, max_tokens=4096,api_key='KVlTLRfckUbPN81UiTC6OPtO1tjzLbC6')"
   ],
   "id": "ecaf508253cb51cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KVlTLRfckUbPN81UiTC6OPtO1tjzLbC6\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:35:40.703139Z",
     "start_time": "2024-06-22T15:35:40.638172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_mistralai.chat_models import ChatMistralAI"
   ],
   "id": "461269bcef0b28cf",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LangSmithParams' from 'langchain_core.language_models.chat_models' (/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmessages\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HumanMessage\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_mistralai\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchat_models\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ChatMistralAI\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/langchain_mistralai/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_mistralai\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchat_models\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ChatMistralAI\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_mistralai\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01membeddings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MistralAIEmbeddings\n\u001B[1;32m      4\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChatMistralAI\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMistralAIEmbeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/langchain_mistralai/chat_models.py:31\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcallbacks\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     27\u001B[0m     AsyncCallbackManagerForLLMRun,\n\u001B[1;32m     28\u001B[0m     CallbackManagerForLLMRun,\n\u001B[1;32m     29\u001B[0m )\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlanguage_models\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LanguageModelInput\n\u001B[0;32m---> 31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlanguage_models\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mchat_models\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     32\u001B[0m     BaseChatModel,\n\u001B[1;32m     33\u001B[0m     LangSmithParams,\n\u001B[1;32m     34\u001B[0m     agenerate_from_stream,\n\u001B[1;32m     35\u001B[0m     generate_from_stream,\n\u001B[1;32m     36\u001B[0m )\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlanguage_models\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mllms\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m create_base_retry_decorator\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmessages\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     39\u001B[0m     AIMessage,\n\u001B[1;32m     40\u001B[0m     AIMessageChunk,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     51\u001B[0m     ToolMessage,\n\u001B[1;32m     52\u001B[0m )\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'LangSmithParams' from 'langchain_core.language_models.chat_models' (/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py)"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from langchain_core.language_models.chat_models import ",
   "id": "e006dc406c39e4a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1edea61409f5a214"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "674c22ada979f98c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T14:11:47.538727Z",
     "start_time": "2024-06-23T14:11:43.272886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from colorama import Fore, Style\n",
    "import pyfiglet\n",
    "\n",
    "# Initialize colorama\n",
    "from colorama import init\n",
    "init()\n",
    "\n",
    "# Fancy title\n",
    "title = pyfiglet.figlet_format(\"Fancy Input\")\n",
    "print(Fore.CYAN + title + Style.RESET_ALL)\n",
    "\n",
    "# Custom input prompt\n",
    "user_name = input(Fore.GREEN + \"Enter your name: \" + Style.RESET_ALL)\n",
    "age = input(Fore.YELLOW + \"Enter your age: \" + Style.RESET_ALL)\n",
    "\n",
    "print(Fore.MAGENTA + f\"Hello, {user_name}! You are {age} years old.\" + Style.RESET_ALL)\n"
   ],
   "id": "9438fa16ab7ccd68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _____                        ___                   _   \n",
      "|  ___|_ _ _ __   ___ _   _  |_ _|_ __  _ __  _   _| |_ \n",
      "| |_ / _` | '_ \\ / __| | | |  | || '_ \\| '_ \\| | | | __|\n",
      "|  _| (_| | | | | (__| |_| |  | || | | | |_) | |_| | |_ \n",
      "|_|  \\__,_|_| |_|\\___|\\__, | |___|_| |_| .__/ \\__,_|\\__|\n",
      "                      |___/            |_|              \n",
      "\n",
      "Hello, sx! You are c years old.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T13:57:38.256863Z",
     "start_time": "2024-06-23T13:57:38.175763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from prompt_toolkit import prompt\n",
    "from prompt_toolkit.completion import WordCompleter\n",
    "from prompt_toolkit.history import FileHistory\n",
    "import asyncio\n",
    "\n",
    "# Example completions\n",
    "commands = ['start', 'stop', 'restart', 'status', 'help']\n",
    "command_completer = WordCompleter(commands, ignore_case=True)\n",
    "\n",
    "# Load input history from a file\n",
    "history = FileHistory('input_history.txt')\n",
    "\n",
    "# Prompt user for input with completion and history\n",
    "user_input = prompt(\n",
    "    'Enter a command: ',\n",
    "    completer=command_completer,\n",
    "    history=history\n",
    ")\n",
    "\n",
    "print(f'You entered: {user_input}')\n",
    "loop = asyncio.get_event_loop()"
   ],
   "id": "6c67cf9455bf41ad",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m history \u001B[38;5;241m=\u001B[39m FileHistory(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minput_history.txt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Prompt user for input with completion and history\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m user_input \u001B[38;5;241m=\u001B[39m \u001B[43mprompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mEnter a command: \u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompleter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommand_completer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhistory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhistory\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mYou entered: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00muser_input\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     21\u001B[0m loop \u001B[38;5;241m=\u001B[39m asyncio\u001B[38;5;241m.\u001B[39mget_event_loop()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/prompt_toolkit/shortcuts/prompt.py:1416\u001B[0m, in \u001B[0;36mprompt\u001B[0;34m(message, history, editing_mode, refresh_interval, vi_mode, lexer, completer, complete_in_thread, is_password, key_bindings, bottom_toolbar, style, color_depth, cursor, include_default_pygments_style, style_transformation, swap_light_and_dark_colors, rprompt, multiline, prompt_continuation, wrap_lines, enable_history_search, search_ignore_case, complete_while_typing, validate_while_typing, complete_style, auto_suggest, validator, clipboard, mouse_support, input_processors, placeholder, reserve_space_for_menu, enable_system_prompt, enable_suspend, enable_open_in_editor, tempfile_suffix, tempfile, default, accept_default, pre_run, set_exception_handler, handle_sigint, in_thread, inputhook)\u001B[0m\n\u001B[1;32m   1412\u001B[0m \u001B[38;5;66;03m# The history is the only attribute that has to be passed to the\u001B[39;00m\n\u001B[1;32m   1413\u001B[0m \u001B[38;5;66;03m# `PromptSession`, it can't be passed into the `prompt()` method.\u001B[39;00m\n\u001B[1;32m   1414\u001B[0m session: PromptSession[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m PromptSession(history\u001B[38;5;241m=\u001B[39mhistory)\n\u001B[0;32m-> 1416\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1417\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmessage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1418\u001B[0m \u001B[43m    \u001B[49m\u001B[43mediting_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mediting_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1419\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrefresh_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrefresh_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1420\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvi_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvi_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1421\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlexer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlexer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1422\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompleter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompleter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1423\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcomplete_in_thread\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomplete_in_thread\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1424\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_password\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_password\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1425\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkey_bindings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey_bindings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1426\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbottom_toolbar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbottom_toolbar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1427\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstyle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstyle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1428\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolor_depth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolor_depth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1429\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcursor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcursor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1430\u001B[0m \u001B[43m    \u001B[49m\u001B[43minclude_default_pygments_style\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_default_pygments_style\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1431\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstyle_transformation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstyle_transformation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1432\u001B[0m \u001B[43m    \u001B[49m\u001B[43mswap_light_and_dark_colors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mswap_light_and_dark_colors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1433\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrprompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1434\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmultiline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmultiline\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1435\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprompt_continuation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprompt_continuation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1436\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwrap_lines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwrap_lines\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1437\u001B[0m \u001B[43m    \u001B[49m\u001B[43menable_history_search\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menable_history_search\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1438\u001B[0m \u001B[43m    \u001B[49m\u001B[43msearch_ignore_case\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msearch_ignore_case\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1439\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcomplete_while_typing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomplete_while_typing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1440\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidate_while_typing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate_while_typing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1441\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcomplete_style\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomplete_style\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1442\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauto_suggest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauto_suggest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1443\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1444\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclipboard\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclipboard\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1445\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmouse_support\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmouse_support\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1446\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_processors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_processors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1447\u001B[0m \u001B[43m    \u001B[49m\u001B[43mplaceholder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mplaceholder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1448\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreserve_space_for_menu\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreserve_space_for_menu\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1449\u001B[0m \u001B[43m    \u001B[49m\u001B[43menable_system_prompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menable_system_prompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1450\u001B[0m \u001B[43m    \u001B[49m\u001B[43menable_suspend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menable_suspend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1451\u001B[0m \u001B[43m    \u001B[49m\u001B[43menable_open_in_editor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menable_open_in_editor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1452\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtempfile_suffix\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtempfile_suffix\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1453\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtempfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtempfile\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1454\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdefault\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1455\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_default\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_default\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1456\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_run\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpre_run\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1457\u001B[0m \u001B[43m    \u001B[49m\u001B[43mset_exception_handler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mset_exception_handler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1458\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhandle_sigint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhandle_sigint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1459\u001B[0m \u001B[43m    \u001B[49m\u001B[43min_thread\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43min_thread\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1460\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputhook\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputhook\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1461\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/prompt_toolkit/shortcuts/prompt.py:1026\u001B[0m, in \u001B[0;36mPromptSession.prompt\u001B[0;34m(self, message, editing_mode, refresh_interval, vi_mode, lexer, completer, complete_in_thread, is_password, key_bindings, bottom_toolbar, style, color_depth, cursor, include_default_pygments_style, style_transformation, swap_light_and_dark_colors, rprompt, multiline, prompt_continuation, wrap_lines, enable_history_search, search_ignore_case, complete_while_typing, validate_while_typing, complete_style, auto_suggest, validator, clipboard, mouse_support, input_processors, placeholder, reserve_space_for_menu, enable_system_prompt, enable_suspend, enable_open_in_editor, tempfile_suffix, tempfile, default, accept_default, pre_run, set_exception_handler, handle_sigint, in_thread, inputhook)\u001B[0m\n\u001B[1;32m   1023\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dumb_prompt(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmessage) \u001B[38;5;28;01mas\u001B[39;00m dump_app:\n\u001B[1;32m   1024\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m dump_app\u001B[38;5;241m.\u001B[39mrun(in_thread\u001B[38;5;241m=\u001B[39min_thread, handle_sigint\u001B[38;5;241m=\u001B[39mhandle_sigint)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1027\u001B[0m \u001B[43m    \u001B[49m\u001B[43mset_exception_handler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mset_exception_handler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1028\u001B[0m \u001B[43m    \u001B[49m\u001B[43min_thread\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43min_thread\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1029\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhandle_sigint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhandle_sigint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1030\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputhook\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputhook\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1031\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/prompt_toolkit/application/application.py:1002\u001B[0m, in \u001B[0;36mApplication.run\u001B[0;34m(self, pre_run, set_exception_handler, handle_sigint, in_thread, inputhook)\u001B[0m\n\u001B[1;32m    998\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m loop\u001B[38;5;241m.\u001B[39mrun_until_complete(coro)\n\u001B[1;32m   1000\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1001\u001B[0m     \u001B[38;5;66;03m# No loop installed. Run like usual.\u001B[39;00m\n\u001B[0;32m-> 1002\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43masyncio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcoro\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/asyncio/runners.py:33\u001B[0m, in \u001B[0;36mrun\u001B[0;34m(main, debug)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \n\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03mThis function runs the passed coroutine, taking care of\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;124;03m    asyncio.run(main())\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m events\u001B[38;5;241m.\u001B[39m_get_running_loop() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m---> 33\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m     34\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124masyncio.run() cannot be called from a running event loop\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m coroutines\u001B[38;5;241m.\u001B[39miscoroutine(main):\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma coroutine was expected, got \u001B[39m\u001B[38;5;132;01m{!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(main))\n",
      "\u001B[0;31mRuntimeError\u001B[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "60844f59e3826afc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
