{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-23T18:27:50.911836Z",
     "start_time": "2024-06-23T18:27:50.909393Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "#collection = os.environ.get('COLLECTION', 'new_youtube_collection').strip()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T18:27:51.192115Z",
     "start_time": "2024-06-23T18:27:51.187171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import uuid\n",
    "session_id = uuid.uuid4()\n",
    "session_id = str(session_id)\n",
    "session_id"
   ],
   "id": "5f45bac4049bca77",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d9732969-fd14-4c6f-b043-9a8c967096b9'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T18:27:51.851454Z",
     "start_time": "2024-06-23T18:27:51.848321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.environ['USER'] = 'postgres'\n",
    "user = os.environ.get('USER', 'postgres').strip()"
   ],
   "id": "e5a9f11c3ae05cc2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgres\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:44:59.254230Z",
     "start_time": "2024-06-22T05:44:59.252153Z"
    }
   },
   "cell_type": "code",
   "source": "#collection",
   "id": "c873393d2d2a08ec",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:45:00.856936Z",
     "start_time": "2024-06-22T05:45:00.118042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import logging\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, CSVLoader\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "#from langchain_openai import OpenAIEmbeddings"
   ],
   "id": "c623677d698f4b03",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:45:47.728835Z",
     "start_time": "2024-06-22T05:45:47.718246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "id": "60cb2e5ead31d200",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T18:28:05.175491Z",
     "start_time": "2024-06-23T18:28:05.173093Z"
    }
   },
   "cell_type": "code",
   "source": "os.getenv(\"MISTRAL_API_KEY\")",
   "id": "af3eaa058412fbab",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:24.623463Z",
     "start_time": "2024-06-21T18:09:24.620806Z"
    }
   },
   "cell_type": "code",
   "source": "model_name=\"mistralai/Mistral-7B-Instruct-v0.1\"",
   "id": "63e58710b4076563",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:24.628146Z",
     "start_time": "2024-06-21T18:09:24.625125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#_, file_extension = os.path.splitext()\n",
    "file_path=\"/Users/mohitverma/Documents/Etech-RAG-Chatbot/Etech-RAG-E2E/qevalprofaq 5.csv\"\n",
    "loader = CSVLoader(file_path)"
   ],
   "id": "edd3d82219c7097b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:24.636356Z",
     "start_time": "2024-06-21T18:09:24.631378Z"
    }
   },
   "cell_type": "code",
   "source": "print(loader.load()[0].page_content)",
   "id": "646d983fef68503",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breadcrumb_title: Can a user view my message if I am replying to some other user in chat feature?\n",
      "post_content: Except for an agent, every user role will have two chat modes on their consoles. These include a Private mode and a general reply mode. A user can use a private mode tab to establish a private conversation for evaluation with other user, thus shielding off other users to view their messages. Similarly, a user can use a reply mode to send the messages, which could be viewed by all the other users.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:24.644112Z",
     "start_time": "2024-06-21T18:09:24.638012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "docs = text_splitter.split_documents(data)"
   ],
   "id": "8533bfbdb29f4386",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:36.234970Z",
     "start_time": "2024-06-21T18:09:24.644976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\"sentence-transformers/all-mpnet-base-v2\")"
   ],
   "id": "4f1bab8f5e9286fa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:36.879394Z",
     "start_time": "2024-06-21T18:09:36.236969Z"
    }
   },
   "cell_type": "code",
   "source": "model=HuggingFaceEndpoint(repo_id=model_name, HUGGINGFACEHUB_API_TOKEN=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"))",
   "id": "1e268aac95f2bd9b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! HUGGINGFACEHUB_API_TOKEN is not default parameter.\n",
      "                    HUGGINGFACEHUB_API_TOKEN was transferred to model_kwargs.\n",
      "                    Please make sure that HUGGINGFACEHUB_API_TOKEN is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/mohitverma/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:37.124411Z",
     "start_time": "2024-06-21T18:09:36.888510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "llm = HuggingFaceEndpoint(repo_id=repo_id,\n",
    "                          max_length=128,\n",
    "                          temperature=0.7)"
   ],
   "id": "ef6cd29971eb67",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /Users/mohitverma/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "`PGVector.from_documents(documents=docs,\n",
    "                                embeddings=HuggingFaceInstructEmbeddings(),)"
   ],
   "id": "9c6eca789866110f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:40.390276Z",
     "start_time": "2024-06-21T18:09:37.127610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ],
   "id": "6f890959b987c51",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:11:57.167685Z",
     "start_time": "2024-06-21T18:11:45.984276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from unittest import loader\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from logger import logging\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, CSVLoader\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.document_loaders import UnstructuredExcelLoader\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from db_connector import connection_string\n",
    "\n",
    "from constants import *\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "#embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "class DataIngestionProcessing:\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def split_data(self):\n",
    "        # Determine the file type based on the extension\n",
    "        _ ,file_extension = os.path.splitext(self.file_path)\n",
    "\n",
    "        if file_extension.lower() == '.csv':\n",
    "            logging.info(f\"Reading CSV file : {self.file_path}\")\n",
    "            print(\"Reading CSV file\")\n",
    "            loader = CSVLoader(self.file_path)\n",
    "\n",
    "        elif file_extension.lower() == '.xlsx':\n",
    "            logging.info(f\"Reading Excel file : {self.file_path}\")\n",
    "            loader=UnstructuredExcelLoader(self.file_path, mode=\"elements\")\n",
    "\n",
    "        elif file_extension.lower() == '.pdf':\n",
    "            logging.info(f\"Reading PDF file {self.file_path}\")\n",
    "            loader=PyPDFLoader(self.file_path)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"File extension {file_extension} not supported\")\n",
    "\n",
    "\n",
    "        data = loader.load()\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size= 1000, chunk_overlap=150)\n",
    "        docs = text_splitter.split_documents(data)\n",
    "        return docs\n",
    "\n",
    "\n",
    "    def push_data(self, docs):\n",
    "        #PGVector.delete_collection(PGSQL_COLLECTION)\n",
    "        print(f\"{self.file_path} is Pushed successfully into {PGSQL_COLLECTION}\")\n",
    "        PGVector.from_documents(\n",
    "            documents=docs,\n",
    "            embedding=embeddings,\n",
    "            collection_name=PGSQL_COLLECTION,\n",
    "            connection_string= connection_string,\n",
    "            pre_delete_collection=False\n",
    "            )\n",
    "        print(f\"{self.file_path} is Pushed successfully into {PGSQL_COLLECTION}\")\n",
    "        \n",
    "    \n",
    "doc_processor = DataIngestionProcessing(file_path=\"/Users/mohitverma/Documents/Etech-RAG-Chatbot/Etech-RAG-E2E/qevalprofaq 5.csv\")\n",
    "docs = doc_processor.split_data()\n",
    "doc_processor.push_data(docs)\n"
   ],
   "id": "e9b7bcf212ac08d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file\n",
      "/Users/mohitverma/Documents/Etech-RAG-Chatbot/Etech-RAG-E2E/qevalprofaq 5.csv is Pushed successfully into etech_collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/langchain_community/vectorstores/pgvector.py:322: LangChainPendingDeprecationWarning: Please use JSONB instead of JSON for metadata. This change will allow for more efficient querying that involves filtering based on metadata.Please note that filtering operators have been changed when using JSOB metadata to be prefixed with a $ sign to avoid name collisions with columns. If you're using an existing database, you will need to create adb migration for your metadata column to be JSONB and update your queries to use the new operators. \n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mohitverma/Documents/Etech-RAG-Chatbot/Etech-RAG-E2E/qevalprofaq 5.csv is Pushed successfully into etech_collection\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T18:09:42.778809Z",
     "start_time": "2024-06-21T18:09:42.778710Z"
    }
   },
   "cell_type": "code",
   "source": "from langchain.embeddings import SentenceTransformerEmbeddings",
   "id": "970bcc6ec6013efe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "52fa184a9ed91e16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def delete_collection(self) -> None:\n",
    "    self.logger.debug(\"Trying to delete collection\")\n",
    "    with Session(self._conn) as session:\n",
    "        collection = self.get_collection(session)\n",
    "        if not collection:\n",
    "            self.logger.warning(\"Collection not found\")\n",
    "            return\n",
    "        session.delete(collection)\n",
    "        session.commit()"
   ],
   "id": "614d387f939aebf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f1465bfc3fc0dbd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:50:52.745519Z",
     "start_time": "2024-06-22T15:50:52.720126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "#from langchain_core.language_models.chat_models import LangSmithParams\n",
    "#from langchain_mistralai.chat_models import ChatMistralAI\n",
    "from langchain_ai21 import ChatAI21\n",
    "from langchain_ai21 import AI21Embeddings\n",
    "#from langchain_mistralai.embeddings import MistralAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# Load data\n",
    "loader = CSVLoader(\"/Users/mohitverma/Documents/Etech-RAG-Chatbot/Etech-RAG-E2E/qevalprofaq 5.csv\")\n",
    "docs = loader.load()\n",
    "# Split text into chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "# Define the embedding model\n",
    "embeddings = AI21Embeddings()\n",
    "# Create the vector store \n",
    "vector = FAISS.from_documents(documents, embeddings)\n",
    "# Define a retriever interface\n",
    "retriever = vector.as_retriever()\n",
    "# Define LLM\n",
    "model = ChatAI21(temperature=0.0, max_tokens=4096)\n",
    "# Define prompt template\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "# Create a retrieval chain to answer questions\n",
    "document_chain = create_stuff_documents_chain(model, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "response = retrieval_chain.invoke({\"input\": \"What were the two main things the author worked on before college?\"})\n",
    "print(response[\"answer\"])"
   ],
   "id": "6127d2bfabf56c60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KVlTLRfckUbPN81UiTC6OPtO1tjzLbC6\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CSVLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAI21_API_KEY\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mKVlTLRfckUbPN81UiTC6OPtO1tjzLbC6\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Load data\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m loader \u001B[38;5;241m=\u001B[39m \u001B[43mCSVLoader\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/Users/mohitverma/Documents/Etech-RAG-Chatbot/Etech-RAG-E2E/qevalprofaq 5.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     21\u001B[0m docs \u001B[38;5;241m=\u001B[39m loader\u001B[38;5;241m.\u001B[39mload()\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Split text into chunks \u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'CSVLoader' is not defined"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T15:55:54.411698Z",
     "start_time": "2024-06-22T15:55:54.349697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embeddings = AI21Embeddings(api_key= os.getenv('AI21_API_KEY'))\n",
    "llm=ChatAI21(model='jamba-instruct',temperature=0.0, max_tokens=4096,api_key=os.getenv('AI21_API_KEY'))"
   ],
   "id": "ecaf508253cb51cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KVlTLRfckUbPN81UiTC6OPtO1tjzLbC6\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T14:11:47.538727Z",
     "start_time": "2024-06-23T14:11:43.272886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from colorama import Fore, Style\n",
    "import pyfiglet\n",
    "\n",
    "# Initialize colorama\n",
    "from colorama import init\n",
    "init()\n",
    "\n",
    "# Fancy title\n",
    "title = pyfiglet.figlet_format(\"Fancy Input\")\n",
    "print(Fore.CYAN + title + Style.RESET_ALL)\n",
    "\n",
    "# Custom input prompt\n",
    "user_name = input(Fore.GREEN + \"Enter your name: \" + Style.RESET_ALL)\n",
    "age = input(Fore.YELLOW + \"Enter your age: \" + Style.RESET_ALL)\n",
    "\n",
    "print(Fore.MAGENTA + f\"Hello, {user_name}! You are {age} years old.\" + Style.RESET_ALL)\n"
   ],
   "id": "9438fa16ab7ccd68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _____                        ___                   _   \n",
      "|  ___|_ _ _ __   ___ _   _  |_ _|_ __  _ __  _   _| |_ \n",
      "| |_ / _` | '_ \\ / __| | | |  | || '_ \\| '_ \\| | | | __|\n",
      "|  _| (_| | | | | (__| |_| |  | || | | | |_) | |_| | |_ \n",
      "|_|  \\__,_|_| |_|\\___|\\__, | |___|_| |_| .__/ \\__,_|\\__|\n",
      "                      |___/            |_|              \n",
      "\n",
      "Hello, sx! You are c years old.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "60844f59e3826afc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
